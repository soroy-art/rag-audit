{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7feeef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Approximate BERTScore using Ollama embeddings (qwen3)\n",
    "# Note: This is an approximation because Ollama embeddings are sentence/phrase-level, not contextual token embeddings.\n",
    "def _simple_tokenize(text: str):\n",
    "    # Lowercase and split into alphanumeric tokens (rough approximation to word pieces)\n",
    "    return re.findall(r\"[A-Za-z0-9]+\", text.lower())\n",
    "\n",
    "def _cosine_matrix(A: np.ndarray, B: np.ndarray):\n",
    "    # Normalize rows and compute cosine similarity matrix A_norm @ B_norm^T\n",
    "    A_norm = A / (np.linalg.norm(A, axis=1, keepdims=True) + 1e-9)\n",
    "    B_norm = B / (np.linalg.norm(B, axis=1, keepdims=True) + 1e-9)\n",
    "    return np.dot(A_norm, B_norm.T)\n",
    "\n",
    "def _ollama_embed_text(text: str, model: str):\n",
    "    import ollama\n",
    "    res = ollama.embeddings(model=model, prompt=text)\n",
    "    # ollama.embeddings returns a dict with 'embedding' key\n",
    "    return np.array(res[\"embedding\"], dtype=np.float32)\n",
    "\n",
    "def _token_embeddings(tokens, model: str, cache: dict):\n",
    "    # Cache to avoid repeated calls for the same token\n",
    "    embs = []\n",
    "    for tok in tokens:\n",
    "        if tok in cache:\n",
    "            emb = cache[tok]\n",
    "        else:\n",
    "            emb = _ollama_embed_text(tok, model)\n",
    "            cache[tok] = emb\n",
    "        embs.append(emb)\n",
    "    return np.vstack(embs) if embs else np.empty((0, 0), dtype=np.float32)\n",
    "\n",
    "def approx_bertscore_ollama(candidate_text: str,\n",
    "                            reference_text: str,\n",
    "                            ollama_model: str = \"qwen3\"):\n",
    "    \"\"\"\n",
    "    Approximate BERTScore using Ollama embeddings by:\n",
    "    - tokenizing each text\n",
    "    - embedding each token independently via Ollama\n",
    "    - computing greedy matching cosine similarities for precision and recall\n",
    "    Returns (precision, recall, f1).\n",
    "\n",
    "    IMPORTANT: This is not true BERTScore because it lacks contextual token embeddings.\n",
    "    \"\"\"\n",
    "    cand_tokens = _simple_tokenize(candidate_text)\n",
    "    ref_tokens = _simple_tokenize(reference_text)\n",
    "\n",
    "    if not cand_tokens or not ref_tokens:\n",
    "        raise ValueError(\"One of the texts has no tokens after tokenization.\")\n",
    "\n",
    "    cache = {}\n",
    "    A = _token_embeddings(cand_tokens, ollama_model, cache)  # shape: n_cand x dim\n",
    "    B = _token_embeddings(ref_tokens, ollama_model, cache)   # shape: n_ref x dim\n",
    "\n",
    "    if A.size == 0 or B.size == 0:\n",
    "        raise RuntimeError(\"Failed to obtain embeddings from Ollama.\")\n",
    "\n",
    "    M = _cosine_matrix(A, B)  # n_cand x n_ref\n",
    "\n",
    "    # Greedy matching like BERTScore (without IDF weighting here)\n",
    "    precision = float(M.max(axis=1).mean())\n",
    "    recall = float(M.max(axis=0).mean())\n",
    "    f1 = 0.0 if (precision + recall) == 0 else float(2 * precision * recall / (precision + recall))\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38898bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example medical texts\n",
    "    candidate = (\n",
    "        \"The patient was started on metformin for newly diagnosed type 2 diabetes. \"\n",
    "        \"Renal function was monitored; eGFR remained stable at 85 mL/min.\"\n",
    "    )\n",
    "    reference = (\n",
    "        \"A new diagnosis of type 2 diabetes led to initiation of metformin therapy. \"\n",
    "        \"Kidney function tests showed a stable estimated GFR of 85 mL/min.\"\n",
    "    )\n",
    "\n",
    "    # 2) Approximate BERTScore via Ollama embeddings (qwen3)\n",
    "    # Ensure Ollama is running locally and the qwen3 embedding model is available:\n",
    "    #   ollama pull qwen3\n",
    "    try:\n",
    "        p_ollama, r_ollama, f1_ollama = approx_bertscore_ollama(candidate, reference, ollama_model=\"qwen3-embedding:latest\")\n",
    "        print(\"\\nApproximate BERTScore via Ollama embeddings (qwen3):\")\n",
    "        print(f\"Precision: {p_ollama:.4f}, Recall: {r_ollama:.4f}, F1: {f1_ollama:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing approximate BERTScore via Ollama: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
