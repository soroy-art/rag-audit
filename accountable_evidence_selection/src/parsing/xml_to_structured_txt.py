import os
from lxml import etree as ET

# --- Configuration ---
# IMPORTANT: Replace these paths with your actual file locations
# Ensure your XML file generated by Grobid is here.
INPUT_XML_FILE = "adult-care-guideline-output/cdc-guidelines-2022-opiods-for-pain.grobid.tei.xml"
OUTPUT_TEXT_FILE = "xml_to_txt_output/cdc-guidelines-2022-opiods-for-pain.txt"

# --- Namespaces ---
# The TEI namespace is CRITICAL for correctly locating elements in GROBID's output.
TEI_NAMESPACE = {'tei': 'http://www.tei-c.org/ns/1.0'}

def extract_table_content(table_element, namespaces):
    """
    Extracts content from a table element and returns formatted text.
    
    Args:
        table_element: XML element representing a table
        namespaces: Dictionary of XML namespaces
        
    Returns:
        str: Formatted table content
    """
    table_content = []
    
    # Extract table header if present
    header_row = table_element.find('.//tei:row[@role="label"]', namespaces=namespaces)
    if header_row is None:
        # Try to find first row as header
        first_row = table_element.find('.//tei:row', namespaces=namespaces)
        if first_row is not None:
            header_row = first_row
    
    if header_row is not None:
        header_cells = header_row.findall('.//tei:cell', namespaces=namespaces)
        if header_cells:
            header_text = " | ".join(["".join(cell.itertext()).strip() for cell in header_cells])
            table_content.append(f"HEADER: {header_text}\n")
            table_content.append("-" * 80 + "\n")
    
    # Extract all rows
    rows = table_element.findall('.//tei:row', namespaces=namespaces)
    for row in rows:
        # Skip header row if we already processed it
        if row == header_row:
            continue
            
        cells = row.findall('.//tei:cell', namespaces=namespaces)
        if cells:
            row_text = " | ".join(["".join(cell.itertext()).strip() for cell in cells])
            if row_text.strip():  # Only add non-empty rows
                table_content.append(f"ROW: {row_text}\n")
    
    return "".join(table_content)

def extract_and_structure_xml(xml_path):
    """
    Reads the GROBID TEI-XML file, extracts key structural elements (sections,
    paragraphs, recommendations), and converts them into a clean, markdown-like
    plain text format for optimal LLM context injection.
    """
    if not os.path.exists(xml_path):    
        return f"Error: Input file not found at {xml_path}"

    print(f"Reading XML file: {xml_path}")
    
    # Use lxml to parse the XML for robust namespace handling
    parser = ET.XMLParser(recover=True)
    tree = ET.parse(xml_path, parser)
    root = tree.getroot()
    
    structured_content = []
    
    # --- 1. Extract Header/Title ---
    # Attempt to find the document title from the header
    title_element = root.find('.//tei:titleStmt/tei:title', namespaces=TEI_NAMESPACE)
    if title_element is not None and title_element.text is not None:
        title_text = title_element.text.strip()
        if title_text:
            structured_content.append(f"# DOCUMENT TITLE: {title_text}\n")
    
    # --- 2. Iterate through the main body divisions ---
    # The primary sections are contained in <div> elements within the <body>
    body_element = root.find('.//tei:body', namespaces=TEI_NAMESPACE)
    
    if body_element is None:
        structured_content.append("\nERROR: Could not find main document body (<tei:body>).")
        return "\n".join(structured_content)

    # Use iterdescendants() to get all sections, subsections, and content elements
    for element in body_element.iterdescendants():
        tag_name = ET.QName(element).localname
        text = (element.text or "").strip()

        if tag_name == 'head' and text:
            # Found a section/subsection header
            structured_content.append(f"\n\n## SECTION: {text.upper()}\n")
            
        elif tag_name == 'p' and text:
            # Found a standard paragraph
            # We strip all internal tags (like <i>, <hi>) but keep the content
            paragraph_text = "".join(element.itertext()).strip()
            structured_content.append(f"PARAGRAPH: {paragraph_text}\n")
            
        elif tag_name == 'item':
            # Found a specific item/recommendation, which is crucial data
            item_text = "".join(element.itertext()).strip()
            
            # Try to find the recommendation grade (e.g., A1, B2) if available, often in the last part of the item text
            # This logic is simplified; a dedicated RegEx search might be needed for accuracy (A1)
            grade = "" # Placeholder for complex logic
            
            structured_content.append(f"* RECOMMENDATION [GRADE {grade}]: {item_text}\n")

        elif tag_name == 'table':
            # Found a standalone table - extract all rows and cells
            structured_content.append("\n--- TABLE ---\n")
            table_text = extract_table_content(element, TEI_NAMESPACE)
            structured_content.append(table_text)
            structured_content.append("--- END TABLE ---\n\n")

        # Ignore lists (<list>) themselves and backmatter sections (<back>)
        elif tag_name in ['list', 'back', 'fig']:
            continue
        
        # Add a newline after the end of a block of content
        elif tag_name == 'div' and element.tail and element.tail.strip():
            structured_content.append("\n" + element.tail.strip() + "\n")

    return "\n".join(structured_content)

def save_structured_text(content, output_path):
    """Saves the structured content to a clean text file."""
    try:
        # Ensure output directory exists
        output_dir = os.path.dirname(output_path)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"\nâœ… Successfully saved structured context to: {output_path}")
    except IOError as e:
        print(f"Error saving output file: {e}")

if __name__ == "__main__":
    # NOTE: You must provide the correct XML file name from your GROBID run!
    # Update this path if the XML file is not in the same directory as this script.
    xml_input_path = os.path.join(os.getcwd(), INPUT_XML_FILE) 
    
    # Run the extraction
    final_content = extract_and_structure_xml(xml_input_path)
    
    if final_content and not final_content.startswith("Error:"):
        # Save the content for the LLM prompt
        save_structured_text(final_content, OUTPUT_TEXT_FILE)
    elif final_content:
        print(final_content) # Print the error message
